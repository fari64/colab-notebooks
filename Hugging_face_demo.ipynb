{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "bbe8d915",
      "metadata": {
        "id": "bbe8d915",
        "outputId": "d25e52a9-9f5b-4c8f-a273-491da8fc3a27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'a black dog laying on top of a wooden floor'}]\n",
            "text: a black dog laying on top of a wooden floor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "story: a black dog laying on top of a wooden floor. I knew I knew nothing: I was on to something. I was not a man. That was too much to bearâ€”a fact I was almost certainly correct about a whole lot of people.\n",
            "\n",
            "The day of my trial, the world was silent. I left and a friend called me back to tell me I am guilty.\n",
            "\n",
            "The week immediately after my guilty plea was announced,\n"
          ]
        }
      ],
      "source": [
        "##Import tha libraries\n",
        "\n",
        "##Import tha libraries\n",
        "\n",
        "from transformers import pipeline # To donwload and us ethe HF model into our local machine\n",
        "\n",
        "\n",
        "\n",
        "# IN our app there are 3 components\n",
        "#1- image 2 text  - The model for the machine  to understand what is the scenario based on a photo\n",
        "def img2text(url): #\n",
        "    image_to_text = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\") # First task-name and then model-name\n",
        "\n",
        "\n",
        "    text = image_to_text(url) # url of the image file\n",
        "\n",
        "    print(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "#text_to_generate = img2text(\"sample_data/image.jpg\")[0][\"generated_text\"]\n",
        "#text_to_generate = img2text(\"https://fastly.picsum.photos/id/866/200/300.jpg?hmac=rcadCENKh4rD6MAp6V_ma-AyWv641M4iiOpe1RyFHeI\")[0][\"generated_text\"]\n",
        "\n",
        "text_to_generate = img2text(\"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\")[0][\"generated_text\"]\n",
        "print(\"text: \" + text_to_generate)\n",
        "\n",
        "#2- llm - Using the model to generate a short story -- Text Genaration model\n",
        "\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "story = generator(text_to_generate, max_length=90, num_return_sequences=1, truncation=True)\n",
        "print(\"story: \" + story[0][\"generated_text\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#3-  text to speech- we are using this model to generate the audio story\n",
        "\n",
        "import requests\n",
        "HUGGINGFACEHUB_API_TOKEN = \"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\"\n",
        "\n",
        "\n",
        "\n",
        "def text2speech(message):\n",
        "  API_URL = \"https://api-inference.huggingface.co/models/espnet/kan-bayashi_ljspeech_vits\"\n",
        "  headers = {\"Authorization\": f\"Bearer {HUGGINGFACEHUB_API_TOKEN}\"}\n",
        "  payloads = {\n",
        "      \"inputs\": message,\n",
        "  }\n",
        "\n",
        "  response = requests.post(API_URL, headers=headers, json=payloads)\n",
        "\n",
        "  with open('audio.flac', 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "\n",
        "text2speech(story)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}