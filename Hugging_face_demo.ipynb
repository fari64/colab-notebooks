{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "JMnQ1tW4AHve"
      },
      "id": "JMnQ1tW4AHve",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "bbe8d915",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbe8d915",
        "outputId": "d16b5f02-398a-487b-871a-28f6cd24bcea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: a black dog laying on top of a wooden floor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "story: a black dog laying on top of a wooden floor. A huge pit bull dog sat directly on top of the pit bull at the side of the building. The pit bulls were constantly harassed, threatened and threatened, but the only thing you could do was say \"stop\" and the police would arrive; there would be no arrest, no summons for animal control, nothing to stop the dogs. Finally the pit bull was shot, but the police tried to\n"
          ]
        }
      ],
      "source": [
        "##Import tha libraries\n",
        "\n",
        "##Import tha libraries\n",
        "\n",
        "from transformers import pipeline # To donwload and us ethe HF model into our local machine\n",
        "\n",
        "\n",
        "\n",
        "# IN our app there are 3 components\n",
        "#1- image 2 text  - The model for the machine  to understand what is the scenario based on a photo\n",
        "def img2text(url): #\n",
        "    image_to_text = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\") # First task-name and then model-name\n",
        "\n",
        "\n",
        "    text = image_to_text(url) # url of the image file\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "#text_to_generate = img2text(\"sample_data/image.jpg\")[0][\"generated_text\"]\n",
        "#text_to_generate = img2text(\"https://fastly.picsum.photos/id/866/200/300.jpg?hmac=rcadCENKh4rD6MAp6V_ma-AyWv641M4iiOpe1RyFHeI\")[0][\"generated_text\"]\n",
        "\n",
        "text_to_generate = img2text(\"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\")[0][\"generated_text\"]\n",
        "print(\"text: \" + text_to_generate)\n",
        "\n",
        "#2- llm - Using the model to generate a short story -- Text Genaration model\n",
        "\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "story = generator(text_to_generate, max_length=90, num_return_sequences=1, truncation=True)\n",
        "print(\"story: \" + story[0][\"generated_text\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#3-  text to speech- we are using this model to generate the audio story\n",
        "\n",
        "import requests\n",
        "HUGGINGFACEHUB_API_TOKEN = \"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\"\n",
        "\n",
        "\n",
        "\n",
        "def text2speech(message):\n",
        "  API_URL = \"https://api-inference.huggingface.co/models/espnet/kan-bayashi_ljspeech_vits\"\n",
        "  headers = {\"Authorization\": f\"Bearer {HUGGINGFACEHUB_API_TOKEN}\"}\n",
        "  payloads = {\n",
        "      \"inputs\": message,\n",
        "  }\n",
        "\n",
        "  response = requests.post(API_URL, headers=headers, json=payloads)\n",
        "\n",
        "  with open('audio.flac', 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "\n",
        "text2speech(story)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}