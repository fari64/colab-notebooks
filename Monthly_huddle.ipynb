
# Import Libraries
#from dotenv import find_dotenv, load_dotenv


# import os
# os.environ['CURL_CA_BUNDLE'] = ''
# os.environ['REQUESTS_CA_BUNDLE'] = ''
# from collections import OrderedDict

from transformers import pipeline # To donwload and us ethe HF model into our local machine

#load_dotenv(find_dotenv()) # To be able to access HF token stored in the file .env

HUGGINGFACEHUB_API_TOKEN = "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"

# IN our app there are 3 components
#1- image 2 text  - The model for the machine  to understand what is the scenario based on a photo
def img2text(url): #
    image_to_text = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base") # First task-name and then model-name
    

    text = image_to_text(url)[0]['generated_text'] # url of the image file

    print(text)

    return text


img2text("image.jpg")


#2- llm - Using the model to generate a short story



#3-  text to speech- we are using this model to generate the audio story